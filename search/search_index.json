{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to fdaPDE functional data analysis with partial differential equation regularization. Pagina home di prova...","title":"Home"},{"location":"#welcome-to-fdapde","text":"functional data analysis with partial differential equation regularization. Pagina home di prova...","title":"Welcome to fdaPDE"},{"location":"Function/","text":"Function","title":"Function"},{"location":"Function/#function","text":"","title":"Function"},{"location":"R/","text":"RfdaPDE This class is the main entry point to the core C++ library from R. Note fdaPDE uses Rcpp and RcppEigen to interface the core library to R. For more informations see Rcpp: Seamless R and C++ Integration RcppEigen: R and Eigen via Rcpp The fdaPDE interface can be loaded from R using the following instructions library(\"Rcpp\") Rcpp::sourceCpp(\"RfdaPDE.cpp\") # create an fdaPDE interface accessible from R fdaPDE_interface = new(RfdaPDE) # you can now access methods using the $ notation fdaPDE_interface$qualcosa ... Interface extension To provide new functionalities to the outside of the C++ core library is required to add a method to the RfdaPDE class working as entry point.","title":"R Interface"},{"location":"R/#rfdapde","text":"This class is the main entry point to the core C++ library from R. Note fdaPDE uses Rcpp and RcppEigen to interface the core library to R. For more informations see Rcpp: Seamless R and C++ Integration RcppEigen: R and Eigen via Rcpp The fdaPDE interface can be loaded from R using the following instructions library(\"Rcpp\") Rcpp::sourceCpp(\"RfdaPDE.cpp\") # create an fdaPDE interface accessible from R fdaPDE_interface = new(RfdaPDE) # you can now access methods using the $ notation fdaPDE_interface$qualcosa ...","title":"RfdaPDE"},{"location":"R/#interface-extension","text":"To provide new functionalities to the outside of the C++ core library is required to add a method to the RfdaPDE class working as entry point.","title":"Interface extension"},{"location":"doc/","text":"Documentation core optimization Optimizer GridOptimizer NewtonOptimizer NewtonForwardDifferenceOptimizer GradientDescentOptimizer mesh handling FEM approximation cose che metto a caso e poi si vede: concetto di funzione o objective function models regression FPCA density estimation interfaces R python in dubbio validation (CV, K-fold CV, GCV) dipendenze Rcpp for R/C++ communication RcppEigen: Rcpp Integration for the Eigen Templated Linear Algebra Library Eigen","title":"Documentation"},{"location":"doc/#documentation","text":"","title":"Documentation"},{"location":"doc/#core","text":"optimization Optimizer GridOptimizer NewtonOptimizer NewtonForwardDifferenceOptimizer GradientDescentOptimizer mesh handling FEM approximation cose che metto a caso e poi si vede: concetto di funzione o objective function","title":"core"},{"location":"doc/#models","text":"regression FPCA density estimation","title":"models"},{"location":"doc/#interfaces","text":"R python","title":"interfaces"},{"location":"doc/#in-dubbio","text":"validation (CV, K-fold CV, GCV)","title":"in dubbio"},{"location":"doc/#dipendenze","text":"Rcpp for R/C++ communication RcppEigen: Rcpp Integration for the Eigen Templated Linear Algebra Library Eigen","title":"dipendenze"},{"location":"start/","text":"Getting started","title":"Getting started"},{"location":"start/#getting-started","text":"","title":"Getting started"},{"location":"core/MESH/","text":"","title":"Index"},{"location":"core/OPT/","text":"Optimization module core/OPT/... Namespace: fdaPDE::core::OPT The optimization module provides a set of general routines for optimizing a generic ScalarField f : \\mathbb{R}^N \\rightarrow \\mathbb{R} . Usage The following code snippet shows how to optimize the scalar field f(x,y) = 3x^3 - 2y^2 + x using a Newton optimizer without providing any analytical expression for its gradient and hessian function (these quantities are numerically approximated by the method at each step): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // define the field analytical expression: 3*x^3 - 2*y^2 + x std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 3 * std :: pow ( x [ 0 ], 3 ) - 2 * std :: pow ( x [ 1 ], 2 ) + x [ 0 ]; }; // wrap the analytical expression in a ScalarField object ScalarField < 2 > field ( g ); // define a newton optimization over a 2-dimensional space unsigned int max_iteration = 10000 ; double tolerance = 0.001 ; // set step sizes for numerical approximation of gradient and hessian double gradient_step = 0.001 ; double hessian_step = 0.001 ; // define optimizer NewtonOptimizer < 2 > Optim ( max_iteration , tolerance , gradient_step , hessian_step ); // set fixed learning rate Optim . setStepSize ( 0.001 ); // compute minimum starting from point (1,1) std :: pair < SVector < 2 > , double > min = Optim . findMinimum ( field , SVector < 2 > ( 1 , 1 )) Developer's advice Due to the highly templatized structure of this module there is no software enforced interface among all optimizers. Future optimizer routines included in this library must adopt the design strategy described in this section to be consistent with the optimization API. A vast family of optimizers should expose their main entry point to the minimization routine using the following signature: template < typename ... Args > std :: pair < SVector < N > , double > findMinimum ( const ScalarField < N >& objective , const SVector < N >& x0 , const Args & ... args ); Args Description const ScalarField<N>& objective The objective function to optimize passed as a ScalarField or one of its derived classes. This last case is adopted in case the optimization scheme requires specific regularity conditions on the objective. const SVector<N>& x0 The initial point from which the iterative method is started. const Args&... args Zero or more Extensions used to control the behaviour of the optimizer at run time. Return type: std::pair<SVector<N>, double> where the first element of the pair is the point of minimum, the second element is the actual value reached by the objective at this minimum. All iterative optimization methods in the OPT module are accessible in this way. In case this is not possible (see for example GridOptimizer ) the signature should be kept as similar as possible to the presented one. Developer's advice In any case is mandatory to expose a findMinimum() method returning a std::pair<SVector<N>, double> and accepting a ScalarField as objective function. Extensions Extensions are a usefull and simple way to modify the behaviour of an optimization routine at run time. Note An optimization method exposing a variadic template findMinimum() method as presented before is open to customizations. See the specific method page to check if an optimizer can be extended or not. Developer's advice Check the Extensions page to find how your optimizer can take advantage of the extension mechanism and how to write new extensions. Consider the case of optimizing the objective function f(x,y) = x^2 + x + y^2 using a GradientDescent optimizer. The following code shows an usage example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // define the field analytical expression: 2*x^2 + x + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + x [ 0 ] + 2 * std :: pow ( x [ 1 ], 2 ); }; // define analytical expression of gradient field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ] + 1 , 4 * x [ 1 ]}); }; // define differentiable scalar field DifferentiableScalarField < 2 > field ( g , dg ); // define a gradient descent optimization over a 2-dimensional space GradientDescentOptimizer < 2 > gradOptim ( 10000 , 0.001 ); // set learning rate to 0.001 gradOptim . setStepSize ( 0.001 ); // compute minimum starting from point (1,1) std :: pair < SVector < 2 > , double > min_Grad = gradOptim . findMinimum ( ddfun , SVector < 2 > ( 1 , 1 )) This code snippet will optimize the function using a fixed learning rate which is the standard behaviour for the gradient descent optimizer. Suppose that the fixed step approach works really bad and you want to go for an adaptive step method based on the same gradient descent iterative scheme. The extension mechanism allows you to inject in the gradient descent algorithm any adaptive step size method. For example, the BacktrackingAdaptiveStep extension implements the backtracking line search algorithm for step selection. Enabling it in the gradient descent method is as simple as writing the following: 1 2 3 // compute minimum starting from point (1,1) using an adaptive backtraking method std :: pair < SVector < 2 > , double > min_Grad = gradOptim . findMinimum ( ddfun , SVector < 2 > ( 1 , 1 ), BacktrackingAdaptiveStep ( 1 , 0.2 , 0.3 )); The code will call the line search algorithm at the right point in the iterative procedure doing all the job for you. You can call as many extensions as you want by simply list them in the findMinimum() method. For example the following applies a backtracking gradient descent method printing at the end of the optimization a small summary of the result 1 2 3 4 5 6 7 8 9 10 11 std :: pair < SVector < 2 > , double > min_Grad = gradOptim . findMinimum ( ddfun , SVector < 2 > ( 1 , 1 ), BacktrackingAdaptiveStep ( 1 , 0.2 , 0.3 ), Summarize ()); >> writes in output Summary of optimization routine type of optimization : Gradient descent method number of iterations : 5 optimium point found : [ -0.249600 , 0.000320 ] objective optimum value : -0.124999 l2 error : 0.00010496 Advice Is up to the user to enable extensions which make sense for the optimization scheme considered and do not collide each other (i.e. enabling more than one adaptive step method is not a good idea). Tip Check the Extensions page to get a list of all available extensions.","title":"Optimization module"},{"location":"core/OPT/#optimization-module","text":"core/OPT/... Namespace: fdaPDE::core::OPT The optimization module provides a set of general routines for optimizing a generic ScalarField f : \\mathbb{R}^N \\rightarrow \\mathbb{R} .","title":"Optimization module"},{"location":"core/OPT/#usage","text":"The following code snippet shows how to optimize the scalar field f(x,y) = 3x^3 - 2y^2 + x using a Newton optimizer without providing any analytical expression for its gradient and hessian function (these quantities are numerically approximated by the method at each step): 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // define the field analytical expression: 3*x^3 - 2*y^2 + x std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 3 * std :: pow ( x [ 0 ], 3 ) - 2 * std :: pow ( x [ 1 ], 2 ) + x [ 0 ]; }; // wrap the analytical expression in a ScalarField object ScalarField < 2 > field ( g ); // define a newton optimization over a 2-dimensional space unsigned int max_iteration = 10000 ; double tolerance = 0.001 ; // set step sizes for numerical approximation of gradient and hessian double gradient_step = 0.001 ; double hessian_step = 0.001 ; // define optimizer NewtonOptimizer < 2 > Optim ( max_iteration , tolerance , gradient_step , hessian_step ); // set fixed learning rate Optim . setStepSize ( 0.001 ); // compute minimum starting from point (1,1) std :: pair < SVector < 2 > , double > min = Optim . findMinimum ( field , SVector < 2 > ( 1 , 1 )) Developer's advice Due to the highly templatized structure of this module there is no software enforced interface among all optimizers. Future optimizer routines included in this library must adopt the design strategy described in this section to be consistent with the optimization API. A vast family of optimizers should expose their main entry point to the minimization routine using the following signature: template < typename ... Args > std :: pair < SVector < N > , double > findMinimum ( const ScalarField < N >& objective , const SVector < N >& x0 , const Args & ... args ); Args Description const ScalarField<N>& objective The objective function to optimize passed as a ScalarField or one of its derived classes. This last case is adopted in case the optimization scheme requires specific regularity conditions on the objective. const SVector<N>& x0 The initial point from which the iterative method is started. const Args&... args Zero or more Extensions used to control the behaviour of the optimizer at run time. Return type: std::pair<SVector<N>, double> where the first element of the pair is the point of minimum, the second element is the actual value reached by the objective at this minimum. All iterative optimization methods in the OPT module are accessible in this way. In case this is not possible (see for example GridOptimizer ) the signature should be kept as similar as possible to the presented one. Developer's advice In any case is mandatory to expose a findMinimum() method returning a std::pair<SVector<N>, double> and accepting a ScalarField as objective function.","title":"Usage"},{"location":"core/OPT/#extensions","text":"Extensions are a usefull and simple way to modify the behaviour of an optimization routine at run time. Note An optimization method exposing a variadic template findMinimum() method as presented before is open to customizations. See the specific method page to check if an optimizer can be extended or not. Developer's advice Check the Extensions page to find how your optimizer can take advantage of the extension mechanism and how to write new extensions. Consider the case of optimizing the objective function f(x,y) = x^2 + x + y^2 using a GradientDescent optimizer. The following code shows an usage example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // define the field analytical expression: 2*x^2 + x + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + x [ 0 ] + 2 * std :: pow ( x [ 1 ], 2 ); }; // define analytical expression of gradient field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ] + 1 , 4 * x [ 1 ]}); }; // define differentiable scalar field DifferentiableScalarField < 2 > field ( g , dg ); // define a gradient descent optimization over a 2-dimensional space GradientDescentOptimizer < 2 > gradOptim ( 10000 , 0.001 ); // set learning rate to 0.001 gradOptim . setStepSize ( 0.001 ); // compute minimum starting from point (1,1) std :: pair < SVector < 2 > , double > min_Grad = gradOptim . findMinimum ( ddfun , SVector < 2 > ( 1 , 1 )) This code snippet will optimize the function using a fixed learning rate which is the standard behaviour for the gradient descent optimizer. Suppose that the fixed step approach works really bad and you want to go for an adaptive step method based on the same gradient descent iterative scheme. The extension mechanism allows you to inject in the gradient descent algorithm any adaptive step size method. For example, the BacktrackingAdaptiveStep extension implements the backtracking line search algorithm for step selection. Enabling it in the gradient descent method is as simple as writing the following: 1 2 3 // compute minimum starting from point (1,1) using an adaptive backtraking method std :: pair < SVector < 2 > , double > min_Grad = gradOptim . findMinimum ( ddfun , SVector < 2 > ( 1 , 1 ), BacktrackingAdaptiveStep ( 1 , 0.2 , 0.3 )); The code will call the line search algorithm at the right point in the iterative procedure doing all the job for you. You can call as many extensions as you want by simply list them in the findMinimum() method. For example the following applies a backtracking gradient descent method printing at the end of the optimization a small summary of the result 1 2 3 4 5 6 7 8 9 10 11 std :: pair < SVector < 2 > , double > min_Grad = gradOptim . findMinimum ( ddfun , SVector < 2 > ( 1 , 1 ), BacktrackingAdaptiveStep ( 1 , 0.2 , 0.3 ), Summarize ()); >> writes in output Summary of optimization routine type of optimization : Gradient descent method number of iterations : 5 optimium point found : [ -0.249600 , 0.000320 ] objective optimum value : -0.124999 l2 error : 0.00010496 Advice Is up to the user to enable extensions which make sense for the optimization scheme considered and do not collide each other (i.e. enabling more than one adaptive step method is not a good idea). Tip Check the Extensions page to get a list of all available extensions.","title":"Extensions"},{"location":"core/OPT/BFGSOptimizer/","text":"","title":"BFGS"},{"location":"core/OPT/DifferentiableScalarField/","text":"DifferentiableScalarField core/OPT/ScalarField.h Extends: ScalarField Template class used to represent a scalar field f : \\mathbb{R}^N \\rightarrow \\mathbb{R} whose gradient function \\nabla f : \\mathbb{R}^N \\rightarrow \\mathbb{R}^N is known analitically at every point. template < unsigned int N > class DifferentiableScalarField : public ScalarField < N > { ... }; Methods DifferentiableScalarField ( std :: function < double ( SVector < N > ) > f_ , std :: function < SVector < N > ( SVector < N > ) > df_ ) Constructor Args Description std::function<double(SVector<N>)> f_ An std::function implementing the analytical expression of the field f taking an N dimensional point in input and returning a double in output std::function<SVector<N>(SVector<N>)> df_ An std::function implementing the analytical expression of the vector field \\nabla f taking an N dimensional point in input and returning an N dimensional point in output representing the gradient expression std :: function < SVector < N > ( SVector < N > ) > derive () const override ; Returns the analytical expression of the field's gradient \\nabla f : \\mathbb{R}^N \\rightarrow \\mathbb{R}^N as a Callable object. Examples Define a scalar field f(x,y) = 2x^2 - 2y^2x having exact gradient equal to \\nabla f = [4x - 2y^2, -4yx]^T 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // define the field analytical expression: 2*x^2 - 2*y^2*x std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) - 2 * std :: pow ( x [ 1 ], 2 ) * x [ 0 ]; }; // define analytical expression of gradient field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ] - 2 * std :: pow ( x [ 1 ], 2 ), -4 * x [ 1 ] * x [ 0 ]}); }; // define differentiable field DifferentiableScalarField < 2 > field ( g , dg ); std :: cout << \"evaluation of field at point\" << std :: endl ; std :: cout << field . evaluateAtPoint ( SVector < 2 > ( 4 , 1 )) << std :: endl ; // get approximation of gradient at point SVector < 2 > grad = field . getGradientApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of gradient at point\" << std :: endl ; std :: cout << grad << std :: endl ; // evaluate exact gradient at point SVector < 2 > exactGrad = field . derive ()( SVector < 2 > ( 2 , 1 )); std :: cout << \"exact gradient at point\" << std :: endl ; std :: cout << exactGrad << std :: endl ;","title":"DifferentiableScalarField"},{"location":"core/OPT/DifferentiableScalarField/#differentiablescalarfield","text":"core/OPT/ScalarField.h Extends: ScalarField Template class used to represent a scalar field f : \\mathbb{R}^N \\rightarrow \\mathbb{R} whose gradient function \\nabla f : \\mathbb{R}^N \\rightarrow \\mathbb{R}^N is known analitically at every point. template < unsigned int N > class DifferentiableScalarField : public ScalarField < N > { ... };","title":"DifferentiableScalarField"},{"location":"core/OPT/DifferentiableScalarField/#methods","text":"DifferentiableScalarField ( std :: function < double ( SVector < N > ) > f_ , std :: function < SVector < N > ( SVector < N > ) > df_ ) Constructor Args Description std::function<double(SVector<N>)> f_ An std::function implementing the analytical expression of the field f taking an N dimensional point in input and returning a double in output std::function<SVector<N>(SVector<N>)> df_ An std::function implementing the analytical expression of the vector field \\nabla f taking an N dimensional point in input and returning an N dimensional point in output representing the gradient expression std :: function < SVector < N > ( SVector < N > ) > derive () const override ; Returns the analytical expression of the field's gradient \\nabla f : \\mathbb{R}^N \\rightarrow \\mathbb{R}^N as a Callable object.","title":"Methods"},{"location":"core/OPT/DifferentiableScalarField/#examples","text":"Define a scalar field f(x,y) = 2x^2 - 2y^2x having exact gradient equal to \\nabla f = [4x - 2y^2, -4yx]^T 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // define the field analytical expression: 2*x^2 - 2*y^2*x std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) - 2 * std :: pow ( x [ 1 ], 2 ) * x [ 0 ]; }; // define analytical expression of gradient field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ] - 2 * std :: pow ( x [ 1 ], 2 ), -4 * x [ 1 ] * x [ 0 ]}); }; // define differentiable field DifferentiableScalarField < 2 > field ( g , dg ); std :: cout << \"evaluation of field at point\" << std :: endl ; std :: cout << field . evaluateAtPoint ( SVector < 2 > ( 4 , 1 )) << std :: endl ; // get approximation of gradient at point SVector < 2 > grad = field . getGradientApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of gradient at point\" << std :: endl ; std :: cout << grad << std :: endl ; // evaluate exact gradient at point SVector < 2 > exactGrad = field . derive ()( SVector < 2 > ( 2 , 1 )); std :: cout << \"exact gradient at point\" << std :: endl ; std :: cout << exactGrad << std :: endl ;","title":"Examples"},{"location":"core/OPT/ExactNewtonOptimizer/","text":"ExactNewtonOptimizer core/OPT/ExactNewtonOptimizer.h Extends: IterativeOptimizer Template class to optimize a given TwiceDifferentiableScalarField over \\mathbb{R}^N using the Newton's iterative optimization method: x_{n+1} = x_{n} - \\lambda H_f(x_n)^{-1} \\cdot \\nabla f(x_n) where H_f(x_n) \\in \\mathbb{R}^{N \\times N} denotes the Hessian matrix of the field evaluated at point x_n . template < unsigned int N > class ExactNewtonOptimizer : public NewtonOptimizer < N > { ... }; Note The implementation of Newton's method provided by this class relies on the exact analytical expression of gradient and hessian of the field. See parent class NewtonOptimizer in case you want to use numerically approximations for these quantities or you have no analytical expressions for them. Info At each iteration of the method to avoid the cost of matrix inversion, the quantity H_f(x_n)^{-1} \\cdot \\nabla f(x_n) is computed by solving the linear system H_f(x_n) z = \\nabla f(x_n) in z using eigen's QR decompostion with column-pivoting . Methods ExactNewtonOptimizer ( double step_ , const SVector < N >& x0_ , unsigned int maxIteration_ , double tolerance_ , const TwiceDifferentiableScalarField < N >& objective_ ) Constructor. Args Description double step_ The term \\lambda in the iterative formulation of the Newton's method. const SVector<N>& x0_ The initial point from which the iterative method is started. unsigned int maxIteration_ The maximum number of iterations allowed. double tolerance_ The tolerance on the error of the obtained solution requested from the method. TwiceDifferentiableScalarField<N>& objective_ The objective function to optimize. std :: pair < SVector < N > , double > findMinimum () const override ; Applies the optimization method to the objective passed as argument. Returns std::pair<SVector<N>,double> where the first element is the point in \\mathbb{R}^N where the minimum is reached while the second one is the actual minimum value reached by the objective. Info Default stopping condition: the method stops either if the l^2 norm of the gradient of the objective \\left\\lVert \\nabla f(x_n) \\right\\rVert reaches the required tolerance or if such tolerance is not reached before a maxIteration number of iterations. Tip You can control the optimizer by exploiting the IterativeOptimizer interface. Examples The following code finds the minimum of function g(x,y) = 2x^2 + x + 2y^2 using an exact Newton's method with \\lambda = 0.01 starting from point (1,1) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // define target to optimize: 2*x^2 + x + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + 2 * std :: pow ( x [ 1 ], 2 ) + x [ 0 ]; }; // define analytical expression of gradient and hessian of the field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ] + 1 , 4 * x [ 1 ]}); }; std :: function < SMatrix < 2 > ( SVector < 2 > ) > ddg = []( SVector < 2 > x ) -> SMatrix < 2 > { return SMatrix < 2 > ({{ 4 , 0 }, { 0 , 4 }}); }; // define the objective to optimize TwiceDifferentiableScalarField < 2 > objective ( g , dg , ddg ); // perform newton optimization double lambda = 0.01 ; // set learning rate unsigned int max_iterations = 1000 ; // set maximum number of iterations double tolerance = 0.001 ; // set tolerance // define newton optimizer ExactNewtonOptimizer < 2 > optNewton2DExact ( lambda , SVector < 2 > ( 1 , 1 ), max_iterations , tolerance , objective ); // optimize std :: pair < SVector < 2 > , double > min_g = optNewton2DExact . findMinimum ();","title":"ExactNewtonOptimizer"},{"location":"core/OPT/ExactNewtonOptimizer/#exactnewtonoptimizer","text":"core/OPT/ExactNewtonOptimizer.h Extends: IterativeOptimizer Template class to optimize a given TwiceDifferentiableScalarField over \\mathbb{R}^N using the Newton's iterative optimization method: x_{n+1} = x_{n} - \\lambda H_f(x_n)^{-1} \\cdot \\nabla f(x_n) where H_f(x_n) \\in \\mathbb{R}^{N \\times N} denotes the Hessian matrix of the field evaluated at point x_n . template < unsigned int N > class ExactNewtonOptimizer : public NewtonOptimizer < N > { ... }; Note The implementation of Newton's method provided by this class relies on the exact analytical expression of gradient and hessian of the field. See parent class NewtonOptimizer in case you want to use numerically approximations for these quantities or you have no analytical expressions for them. Info At each iteration of the method to avoid the cost of matrix inversion, the quantity H_f(x_n)^{-1} \\cdot \\nabla f(x_n) is computed by solving the linear system H_f(x_n) z = \\nabla f(x_n) in z using eigen's QR decompostion with column-pivoting .","title":"ExactNewtonOptimizer"},{"location":"core/OPT/ExactNewtonOptimizer/#methods","text":"ExactNewtonOptimizer ( double step_ , const SVector < N >& x0_ , unsigned int maxIteration_ , double tolerance_ , const TwiceDifferentiableScalarField < N >& objective_ ) Constructor. Args Description double step_ The term \\lambda in the iterative formulation of the Newton's method. const SVector<N>& x0_ The initial point from which the iterative method is started. unsigned int maxIteration_ The maximum number of iterations allowed. double tolerance_ The tolerance on the error of the obtained solution requested from the method. TwiceDifferentiableScalarField<N>& objective_ The objective function to optimize. std :: pair < SVector < N > , double > findMinimum () const override ; Applies the optimization method to the objective passed as argument. Returns std::pair<SVector<N>,double> where the first element is the point in \\mathbb{R}^N where the minimum is reached while the second one is the actual minimum value reached by the objective. Info Default stopping condition: the method stops either if the l^2 norm of the gradient of the objective \\left\\lVert \\nabla f(x_n) \\right\\rVert reaches the required tolerance or if such tolerance is not reached before a maxIteration number of iterations. Tip You can control the optimizer by exploiting the IterativeOptimizer interface.","title":"Methods"},{"location":"core/OPT/ExactNewtonOptimizer/#examples","text":"The following code finds the minimum of function g(x,y) = 2x^2 + x + 2y^2 using an exact Newton's method with \\lambda = 0.01 starting from point (1,1) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // define target to optimize: 2*x^2 + x + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + 2 * std :: pow ( x [ 1 ], 2 ) + x [ 0 ]; }; // define analytical expression of gradient and hessian of the field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ] + 1 , 4 * x [ 1 ]}); }; std :: function < SMatrix < 2 > ( SVector < 2 > ) > ddg = []( SVector < 2 > x ) -> SMatrix < 2 > { return SMatrix < 2 > ({{ 4 , 0 }, { 0 , 4 }}); }; // define the objective to optimize TwiceDifferentiableScalarField < 2 > objective ( g , dg , ddg ); // perform newton optimization double lambda = 0.01 ; // set learning rate unsigned int max_iterations = 1000 ; // set maximum number of iterations double tolerance = 0.001 ; // set tolerance // define newton optimizer ExactNewtonOptimizer < 2 > optNewton2DExact ( lambda , SVector < 2 > ( 1 , 1 ), max_iterations , tolerance , objective ); // optimize std :: pair < SVector < 2 > , double > min_g = optNewton2DExact . findMinimum ();","title":"Examples"},{"location":"core/OPT/Extensions/","text":"Extensions This page contains more detailed informations about available extensions and how to extending an already existing optimizer by writing a new extension. Available Extensions core/OPT/extensions/... Namespace: fdaPDE::core::OPT This is the list of currently available extensions: BacktrackingAdaptiveStep core/OPT/extensions/BacktrackingAdaptiveStep.h Extends: - This extension is for enabling the backtracking line search method to adapt the step size of an iterative optimizer during execution. For a function f : \\mathbb{R}^N \\rightarrow \\mathbb{R} whose gradient is known, given an iterative optimization scheme: x_{k+1} = x_k + \\lambda_k p_k Let \\alpha, \\beta and \\gamma three fixed parameters. Given x_k the current solution of the iterative method and p_k the computed update direction, the backtraking method computes \\lambda_k before computing the solution update x_{k+1} by producing a sequence \\alpha_k using the following scheme: set \\alpha_0 = \\alpha and i = 1 let \\alpha_i = \\beta \\alpha_{i-1} if f(x_k) - f( x - \\alpha_i \\nabla f(x_k) ) + \\gamma \\alpha_i \\langle \\nabla f(x_k), p_k \\rangle < 0 stop and set \\lambda_k = \\alpha_i , otherwise increment i by one and repeat from the previous point. Info The extension injects the computation in the InitIteration checkpoint of the iterative procedure. BacktrackingAdaptiveStep ( double alpha_ , double beta_ , double gamma_ ); Constructor. Args Description double alpha_ The \\alpha value in the backtracking method (i.e. the starting point for the line search algorithm). double beta_ The \\beta value in the backtracking method. Should be a value in between 0 and 1. double gamma_ The \\gamma value in the backtracking method. Should be a value in between 0 and 1. Note The class provides also a default constructor which sets the three parameters to some default value. Parameter selection is really probelm specific and default initialization should be avoided. Summarize core/OPT/extensions/Summarize.h Extends: - An extension to report a small result of the optimization procedure. Info The extension injects the computation in the EndOptimization checkpoint of the iterative procedure. Write a new extension Info When the code finds a class intended to be an extension passed as argument to the optimizer's entry point it looks inside its definition to search for a well defined set of methods which will be then called in a well defined position. All happens at compile-time with no run-time overhead. You can refer to the following snippet as basic footprint for future extensions: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #ifndef __MYEXT_H__ #define __MYEXT_H__ ... class MyExt { private : ... some internal state of the extension ... public : MyExt () = default ; template < typename Optimizer , typename Objective > bool initOptimization ( Optimizer & opt , Objective & obj ){ /* this will be called at the start of the optimization */ return false ; } template < typename Optimizer , typename Objective > bool initIteration ( Optimizer & opt , Objective & obj ){ /* this will be called at the start of each iteration */ return false ; } template < typename Optimizer , typename Objective > bool endIteration ( Optimizer & opt , Objective & obj ){ /* this will be called at the end of each iteration */ return false ; } template < typename Optimizer , typename Objective > bool endOptimization ( Optimizer & opt , Objective & obj ){ /* this will be called at the end of the optimization */ return false ; } ... other methods ... }; #endif // __MYEXT_H__ The return value of each method is used to stop the optimization at any point (i.e. you can make one method to return true if you want to stop the optimization procedure). Developer's advice In case the extension has effect in just one single phase of the optimization scheme you can avoid (and this is recommended) to define all the other checkpoint methods. Make an optimizer open to extensions An optimizer which supports the extension mechanism must have a variadic templated signature for its entry point as follow: template < typename ... Args > std :: pair < SVector < N > , double > findMinimum ( const ScalarField < N >& objective , const SVector < N >& x0 , const Args & ... args ); Another condition to make the implementation in the position to process possible extensions passed as input is to insert in the implementation of findMinimum() a well defined set of static members (provided by core/OPT/extensions/Extension.h ) which will activate the extension machinery. You can refer to the following snippet as basic footprint for an extensible optimizer: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 template < unsigned int N > template < typename ... Args > std :: pair < SVector < N > , double > findMinimum ( const ScalarField < N >& objective , const SVector < N >& x0 , const Args & ... args ){ bool customStop = false ; customStop |= Extension :: executeInitOptimization ( * this , objective , args ...); ... initialization ... while (... && ! customStop ){ customStop |= Extension :: executeInitIteration ( * this , objective , args ...); ... optimization logic ... customStop |= Extension :: executeEndIteration ( * this , objective , args ...); } Extension :: executeEndOptimization ( * this , objective , args ...); return ...; } Note The position in which checkpoints are inserted is the one commonly adopted in the whole module. You can change the position according to your needs even if is recommended to mantain this scheme in order to have a consistent logic across different optimizers.","title":"Extensions"},{"location":"core/OPT/Extensions/#extensions","text":"This page contains more detailed informations about available extensions and how to extending an already existing optimizer by writing a new extension.","title":"Extensions"},{"location":"core/OPT/Extensions/#available-extensions","text":"core/OPT/extensions/... Namespace: fdaPDE::core::OPT This is the list of currently available extensions: BacktrackingAdaptiveStep core/OPT/extensions/BacktrackingAdaptiveStep.h Extends: - This extension is for enabling the backtracking line search method to adapt the step size of an iterative optimizer during execution. For a function f : \\mathbb{R}^N \\rightarrow \\mathbb{R} whose gradient is known, given an iterative optimization scheme: x_{k+1} = x_k + \\lambda_k p_k Let \\alpha, \\beta and \\gamma three fixed parameters. Given x_k the current solution of the iterative method and p_k the computed update direction, the backtraking method computes \\lambda_k before computing the solution update x_{k+1} by producing a sequence \\alpha_k using the following scheme: set \\alpha_0 = \\alpha and i = 1 let \\alpha_i = \\beta \\alpha_{i-1} if f(x_k) - f( x - \\alpha_i \\nabla f(x_k) ) + \\gamma \\alpha_i \\langle \\nabla f(x_k), p_k \\rangle < 0 stop and set \\lambda_k = \\alpha_i , otherwise increment i by one and repeat from the previous point. Info The extension injects the computation in the InitIteration checkpoint of the iterative procedure. BacktrackingAdaptiveStep ( double alpha_ , double beta_ , double gamma_ ); Constructor. Args Description double alpha_ The \\alpha value in the backtracking method (i.e. the starting point for the line search algorithm). double beta_ The \\beta value in the backtracking method. Should be a value in between 0 and 1. double gamma_ The \\gamma value in the backtracking method. Should be a value in between 0 and 1. Note The class provides also a default constructor which sets the three parameters to some default value. Parameter selection is really probelm specific and default initialization should be avoided. Summarize core/OPT/extensions/Summarize.h Extends: - An extension to report a small result of the optimization procedure. Info The extension injects the computation in the EndOptimization checkpoint of the iterative procedure.","title":"Available Extensions"},{"location":"core/OPT/Extensions/#write-a-new-extension","text":"Info When the code finds a class intended to be an extension passed as argument to the optimizer's entry point it looks inside its definition to search for a well defined set of methods which will be then called in a well defined position. All happens at compile-time with no run-time overhead. You can refer to the following snippet as basic footprint for future extensions: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #ifndef __MYEXT_H__ #define __MYEXT_H__ ... class MyExt { private : ... some internal state of the extension ... public : MyExt () = default ; template < typename Optimizer , typename Objective > bool initOptimization ( Optimizer & opt , Objective & obj ){ /* this will be called at the start of the optimization */ return false ; } template < typename Optimizer , typename Objective > bool initIteration ( Optimizer & opt , Objective & obj ){ /* this will be called at the start of each iteration */ return false ; } template < typename Optimizer , typename Objective > bool endIteration ( Optimizer & opt , Objective & obj ){ /* this will be called at the end of each iteration */ return false ; } template < typename Optimizer , typename Objective > bool endOptimization ( Optimizer & opt , Objective & obj ){ /* this will be called at the end of the optimization */ return false ; } ... other methods ... }; #endif // __MYEXT_H__ The return value of each method is used to stop the optimization at any point (i.e. you can make one method to return true if you want to stop the optimization procedure). Developer's advice In case the extension has effect in just one single phase of the optimization scheme you can avoid (and this is recommended) to define all the other checkpoint methods.","title":"Write a new extension"},{"location":"core/OPT/Extensions/#make-an-optimizer-open-to-extensions","text":"An optimizer which supports the extension mechanism must have a variadic templated signature for its entry point as follow: template < typename ... Args > std :: pair < SVector < N > , double > findMinimum ( const ScalarField < N >& objective , const SVector < N >& x0 , const Args & ... args ); Another condition to make the implementation in the position to process possible extensions passed as input is to insert in the implementation of findMinimum() a well defined set of static members (provided by core/OPT/extensions/Extension.h ) which will activate the extension machinery. You can refer to the following snippet as basic footprint for an extensible optimizer: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 template < unsigned int N > template < typename ... Args > std :: pair < SVector < N > , double > findMinimum ( const ScalarField < N >& objective , const SVector < N >& x0 , const Args & ... args ){ bool customStop = false ; customStop |= Extension :: executeInitOptimization ( * this , objective , args ...); ... initialization ... while (... && ! customStop ){ customStop |= Extension :: executeInitIteration ( * this , objective , args ...); ... optimization logic ... customStop |= Extension :: executeEndIteration ( * this , objective , args ...); } Extension :: executeEndOptimization ( * this , objective , args ...); return ...; } Note The position in which checkpoints are inserted is the one commonly adopted in the whole module. You can change the position according to your needs even if is recommended to mantain this scheme in order to have a consistent logic across different optimizers.","title":"Make an optimizer open to extensions"},{"location":"core/OPT/GradientDescentOptimizer/","text":"","title":"GradientDescentOptimizer"},{"location":"core/OPT/GridOptimizer/","text":"GridOptimizer core/OPT/optimizers/Grid.h Extends: - Template class to optimize a given ScalarField over an N-dimensional grid of equidistant nodes. template < unsigned int N > class GridOptimizer { ... }; The class simulates the construction of an N-dimensional rectangle [a_1, b_1] \\times \\ldots \\times [a_N, b_N] splitted along each interval according to a given grid step (the grid step can possibly differ for each dimension). The search is performed using an exhaustive search over the N-dimensional grid. Warning Since this optimization algorithm applies just an exhaustive search without any heuristic the resulting time complexity is exponential in the dimension of the grid N. The method can be very slow for values of N bigger than 2. Methods GridOptimizer ( std :: array < std :: pair < double , double > , N > domain , std :: array < double , N > steps , const ScalarField < N >& objective_ ) Constructor. It sets the shape of the domain where to search for the optimum of the objective as well as the grid step for each dimension. Args Description std::array<std::pair<double,double>,N> An array of exactly N pairs where pair i represents infimum and superior limit of the interval [a_i, b_i] along the i -th dimension std::array<double,N> steps An array of exactly N doubles where the i -th element defines the grid step along the i -th dimension const ScalarField<N>& objective_ The objective function to optimize std :: pair < SVector < N > , double > findMinimum () override ; Apply the search strategy to the objective passed as argument. Returns std::pair<SVector<N>,double> where the first element is the point in the grid where the minimum is reached while the second one is the actual minimum value reached by the objective. Info During the search no grid is actually stored in memory making the call at least memory efficient. Examples The following code finds the minimum of function g(x,y) = 2x^2 - 2y^2 over a grid of points defined in [1,5] \\times [1,5] \\subset \\mathbb{R}^2 with grid step 0.01 for each dimension 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // define target to optimize: 2*x^2 - 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) - 2 * std :: pow ( x [ 1 ], 2 ); }; // create a scalar field ScalarField < 2 > objective ( g ); // perform a 2D grid optimization // set optimization domain: [1,5] x [1,5] std :: array < std :: pair < double , double > , 2 > domain2D = { std :: pair < double , double > ( 1 , 5 ), std :: pair < double , double > ( 1 , 5 ) }; // set grid step size std :: array < double , 2 > step2D = { 0.01 , 0.01 }; // create optimizer GridOptimizer < 2 > opt2D ( domain2D , lambda2D , objective ); // find minimum of g std :: pair < array < double , 2 > , double > min_g = opt2D . findMinimum ();","title":"GridOptimizer"},{"location":"core/OPT/GridOptimizer/#gridoptimizer","text":"core/OPT/optimizers/Grid.h Extends: - Template class to optimize a given ScalarField over an N-dimensional grid of equidistant nodes. template < unsigned int N > class GridOptimizer { ... }; The class simulates the construction of an N-dimensional rectangle [a_1, b_1] \\times \\ldots \\times [a_N, b_N] splitted along each interval according to a given grid step (the grid step can possibly differ for each dimension). The search is performed using an exhaustive search over the N-dimensional grid. Warning Since this optimization algorithm applies just an exhaustive search without any heuristic the resulting time complexity is exponential in the dimension of the grid N. The method can be very slow for values of N bigger than 2.","title":"GridOptimizer"},{"location":"core/OPT/GridOptimizer/#methods","text":"GridOptimizer ( std :: array < std :: pair < double , double > , N > domain , std :: array < double , N > steps , const ScalarField < N >& objective_ ) Constructor. It sets the shape of the domain where to search for the optimum of the objective as well as the grid step for each dimension. Args Description std::array<std::pair<double,double>,N> An array of exactly N pairs where pair i represents infimum and superior limit of the interval [a_i, b_i] along the i -th dimension std::array<double,N> steps An array of exactly N doubles where the i -th element defines the grid step along the i -th dimension const ScalarField<N>& objective_ The objective function to optimize std :: pair < SVector < N > , double > findMinimum () override ; Apply the search strategy to the objective passed as argument. Returns std::pair<SVector<N>,double> where the first element is the point in the grid where the minimum is reached while the second one is the actual minimum value reached by the objective. Info During the search no grid is actually stored in memory making the call at least memory efficient.","title":"Methods"},{"location":"core/OPT/GridOptimizer/#examples","text":"The following code finds the minimum of function g(x,y) = 2x^2 - 2y^2 over a grid of points defined in [1,5] \\times [1,5] \\subset \\mathbb{R}^2 with grid step 0.01 for each dimension 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // define target to optimize: 2*x^2 - 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) - 2 * std :: pow ( x [ 1 ], 2 ); }; // create a scalar field ScalarField < 2 > objective ( g ); // perform a 2D grid optimization // set optimization domain: [1,5] x [1,5] std :: array < std :: pair < double , double > , 2 > domain2D = { std :: pair < double , double > ( 1 , 5 ), std :: pair < double , double > ( 1 , 5 ) }; // set grid step size std :: array < double , 2 > step2D = { 0.01 , 0.01 }; // create optimizer GridOptimizer < 2 > opt2D ( domain2D , lambda2D , objective ); // find minimum of g std :: pair < array < double , 2 > , double > min_g = opt2D . findMinimum ();","title":"Examples"},{"location":"core/OPT/NewtonOptimizer/","text":"NewtonOptimizer core/OPT/NewtonOptimizer.h Extends: IterativeOptimizer Template class to optimize a given ScalarField over \\mathbb{R}^N using the Newton's iterative optimization method: x_{n+1} = x_{n} - \\lambda H_f(x_n)^{-1} \\cdot \\nabla f(x_n) where H_f(x_n) \\in \\mathbb{R}^{N \\times N} denotes the Hessian matrix of the field evaluated at point x_n . template < unsigned int N > class NewtonOptimizer { ... }; Note The implementation of Newton's method provided by this class works by numerically approximating both gradient and hessian of the field at the given point. See ExactNewtonOptimizer in case you want to use the analytical expression of these quantites during the iterative process Info At each iteration of the method to avoid the cost of matrix inversion, the quantity H_f(x_n)^{-1} \\cdot \\nabla f(x_n) is computed by solving the linear system H_f(x_n) z = \\nabla f(x_n) in z using eigen's QR decompostion with column-pivoting . Methods NewtonOptimizer ( double step_ , const SVector < N >& x0_ , unsigned int maxIteration_ , double tolerance_ , const ScalarField < N >& objective_ ) Constructor. Args Description double step_ The term \\lambda in the iterative formulation of the Newton's method. const SVector<N>& x0 The initial point from which the iterative method is started. unsigned int maxIteration The maximum number of iterations allowed. double tolerance The tolerance on the error of the obtained solution requested from the method. ScalarField<N>& objective The objective function to optimize. std :: pair < SVector < N > , double > findMinimum () override ; Applies the optimization method to the objective passed as argument. Returns std::pair<SVector<N>,double> where the first element is the point in \\mathbb{R}^N where the minimum is reached while the second one is the actual minimum value reached by the objective. Info Default stopping condition: the method stops either if the l^2 norm of the gradient of the objective \\left\\lVert \\nabla f(x_n) \\right\\rVert reaches the required tolerance or if such tolerance is not reached before a maxIteration number of iterations. Tip You can control the optimizer by exploiting the IterativeOptimizer interface. Examples The following code finds the minimum of function g(x,y) = 2x^2 + x + 2y^2 using Newton's method with \\lambda = 0.01 starting from point (1,1) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // define target to optimize: 2*x^2 + x + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + 2 * std :: pow ( x [ 1 ], 2 ) + x [ 0 ]; }; // wrap target in a ScalarField object ScalarField < 2 > objective ( g ); // perform newton optimization double lambda = 0.01 ; // learning rate unsigned int max_iterations = 1000 ; // max number of iterations double tolerance = 0.001 ; // tolerance // create optimizer NewtonOptimizer < 2 > optNewton2D ( lambda , SVector < 2 > ( 1 , 1 ), max_iterations , tolerance , objective ); // find minimum of objective std :: pair < SVector < 2 > , double > min_g = optNewton2D . findMinimum ();","title":"NewtonOptimizer"},{"location":"core/OPT/NewtonOptimizer/#newtonoptimizer","text":"core/OPT/NewtonOptimizer.h Extends: IterativeOptimizer Template class to optimize a given ScalarField over \\mathbb{R}^N using the Newton's iterative optimization method: x_{n+1} = x_{n} - \\lambda H_f(x_n)^{-1} \\cdot \\nabla f(x_n) where H_f(x_n) \\in \\mathbb{R}^{N \\times N} denotes the Hessian matrix of the field evaluated at point x_n . template < unsigned int N > class NewtonOptimizer { ... }; Note The implementation of Newton's method provided by this class works by numerically approximating both gradient and hessian of the field at the given point. See ExactNewtonOptimizer in case you want to use the analytical expression of these quantites during the iterative process Info At each iteration of the method to avoid the cost of matrix inversion, the quantity H_f(x_n)^{-1} \\cdot \\nabla f(x_n) is computed by solving the linear system H_f(x_n) z = \\nabla f(x_n) in z using eigen's QR decompostion with column-pivoting .","title":"NewtonOptimizer"},{"location":"core/OPT/NewtonOptimizer/#methods","text":"NewtonOptimizer ( double step_ , const SVector < N >& x0_ , unsigned int maxIteration_ , double tolerance_ , const ScalarField < N >& objective_ ) Constructor. Args Description double step_ The term \\lambda in the iterative formulation of the Newton's method. const SVector<N>& x0 The initial point from which the iterative method is started. unsigned int maxIteration The maximum number of iterations allowed. double tolerance The tolerance on the error of the obtained solution requested from the method. ScalarField<N>& objective The objective function to optimize. std :: pair < SVector < N > , double > findMinimum () override ; Applies the optimization method to the objective passed as argument. Returns std::pair<SVector<N>,double> where the first element is the point in \\mathbb{R}^N where the minimum is reached while the second one is the actual minimum value reached by the objective. Info Default stopping condition: the method stops either if the l^2 norm of the gradient of the objective \\left\\lVert \\nabla f(x_n) \\right\\rVert reaches the required tolerance or if such tolerance is not reached before a maxIteration number of iterations. Tip You can control the optimizer by exploiting the IterativeOptimizer interface.","title":"Methods"},{"location":"core/OPT/NewtonOptimizer/#examples","text":"The following code finds the minimum of function g(x,y) = 2x^2 + x + 2y^2 using Newton's method with \\lambda = 0.01 starting from point (1,1) . 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // define target to optimize: 2*x^2 + x + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + 2 * std :: pow ( x [ 1 ], 2 ) + x [ 0 ]; }; // wrap target in a ScalarField object ScalarField < 2 > objective ( g ); // perform newton optimization double lambda = 0.01 ; // learning rate unsigned int max_iterations = 1000 ; // max number of iterations double tolerance = 0.001 ; // tolerance // create optimizer NewtonOptimizer < 2 > optNewton2D ( lambda , SVector < 2 > ( 1 , 1 ), max_iterations , tolerance , objective ); // find minimum of objective std :: pair < SVector < 2 > , double > min_g = optNewton2D . findMinimum ();","title":"Examples"},{"location":"core/OPT/Optimizer/","text":"The optimization module provides a set of general routines for optimizing a generic ScalarField f : \\mathbb{R}^N \\rightarrow \\mathbb{R} . Optimizer core/OPT/Optimizer.h Extends: - Base interface for the whole optimization module. template < unsigned int N > class Optimizer { ... }; Info The template parameter N denotes the dimension of the space where to search for the optimum point. This information should be known at compile time in order to define the data structure required during the optimization. Developer's advice Any class meant to work as an optimizer must derive this class or one of its direct child classes. Methods offered by the interface virtual std :: pair < SVector < N > , double > findMinimum (); The main entry point for the optimization routine. A call to this method should produce as output a std::pair<SVector<N>, double> where the first component is the point where the minimum of the objective is reached while the second component is the actual minimum value found. The algorithm used for producing the result is implementation dependent. IterativeOptimizer core/OPT/IterativeOptimizer.h Extends: Optimizer Template abstract class representing a general iterative optimizer. An iterative optimizer is any optimization routine which can be schematized as follow: 1 2 3 4 5 6 7 8 9 let x [ 0 ] the starting point let k = 0 while ( some stopping condition is not met ){ // update the current solution x [ k + 1 ] = x [ k ] + a [ k ] * d [ k ]; k ++ ; } return x [ k ]; Even if algorithms can drammatically differ in the computation of the update step this general footprint is still mantained. For this reason a rich family of optimization algorithms fall under this class. The IterativeOptimizer interface should be used to inform the user that an iterative optimization procedure is implemented under the hood. template < unsigned int N > class IterativeOptimizer : public Optimizer < N > { ... }; Info The IterativeOptimizer class does not implement the general schema of an iterative optimizer, whose implementation is left to the derived classes. Forcing any deriving class to follow a too rigid schema could introduce useless complications in the implementation of the optimization procedure. This class introduce anyway the possibility to control in some way the flow of execution of an iterative optimizer. For example it would be possible to monitor during the execution of the algorithm itself some quantities of interest for the particular problem at hand and force the stop of the procedure on the base of some custom stopping criterion bypassing the default one. The way this mechanism is reached is by extending any concrete implementation of the IterativeOptimizer class and overloading the wanted methods exposed by IterativeOptimizer itself. Developer's advice Is up to the derived classes of IterativeOptimizer to implement properly the stated mechanism. When you want to give the possibility to execute a (possibly) custom action of a (possibly) deriving class you should insert i.e. this->init() for executing a custom initialization. See the semantic of IterativeOptimizer ' methods to see what kind of customizations can be added and decide the proper place where to execute the action. Methods virtual void init (); This method should be called once before entering the iterative loop. virtual void preStep (); This method should be inserted in the iterative loop, possibly as first loop instruction. In any case insert it before the update step. virtual void postStep (); This method should be inserted in the iterative loop. Insert it after the update step. A good place is immediately after the error update. virtual bool stopCondition (); This method should be called in a while of for statement togheter with the default termination criteria. The good practice is to write something like while ( ! default_stopping_condition () && ! this -> stopCondition ()) { ... } It must return false if the custom stopping condition is not met. virtual void finalize (); This method should be called once outside the iterative loop, possibly right before the return statement. As an example consider the implementation of the optimization routine for the GradientDescent 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // gradient descent optimization routine template < unsigned int N > std :: pair < SVector < N > , double > GradientDescentOptimizer < N >:: findMinimum (){ this -> init (); // execute custom action // algorithm initialization x_old = x0 ; unsigned int numIteration = 0 ; // standard termination criteria based on l^2 norm of the gradient error = objective . derive ()( x_old ). squaredNorm (); while ( numIteration < maxIteration && error > tolerance && ! this -> stopCondition ()){ this -> preStep (); // execute custom action // compute exact gradient gradientExact = objective . derive ()( x_old ); // update step x_new = x_old - step * gradientExact ; // error update: standard termination criteria based on l^2 norm of the gradient error = gradientExact . squaredNorm (); this -> postStep (); // execute custom action // prepare next iteration x_old = x_new ; numIteration ++ ; } this -> finalize (); // execute custom action return std :: pair < SVector < N > , double > ( x_old , objective ( x_old )); } Tip The IterativeOptimizer class offers a std::unordered_map<std::string, std::list<double>> controllerData which can be used by a customization to store or record values needed to perform custom actions. Use the init() method to initialize any field you might require before the actual optimization starts.","title":"Optimizer"},{"location":"core/OPT/Optimizer/#optimizer","text":"core/OPT/Optimizer.h Extends: - Base interface for the whole optimization module. template < unsigned int N > class Optimizer { ... }; Info The template parameter N denotes the dimension of the space where to search for the optimum point. This information should be known at compile time in order to define the data structure required during the optimization. Developer's advice Any class meant to work as an optimizer must derive this class or one of its direct child classes.","title":"Optimizer"},{"location":"core/OPT/Optimizer/#methods-offered-by-the-interface","text":"virtual std :: pair < SVector < N > , double > findMinimum (); The main entry point for the optimization routine. A call to this method should produce as output a std::pair<SVector<N>, double> where the first component is the point where the minimum of the objective is reached while the second component is the actual minimum value found. The algorithm used for producing the result is implementation dependent.","title":"Methods offered by the interface"},{"location":"core/OPT/Optimizer/#iterativeoptimizer","text":"core/OPT/IterativeOptimizer.h Extends: Optimizer Template abstract class representing a general iterative optimizer. An iterative optimizer is any optimization routine which can be schematized as follow: 1 2 3 4 5 6 7 8 9 let x [ 0 ] the starting point let k = 0 while ( some stopping condition is not met ){ // update the current solution x [ k + 1 ] = x [ k ] + a [ k ] * d [ k ]; k ++ ; } return x [ k ]; Even if algorithms can drammatically differ in the computation of the update step this general footprint is still mantained. For this reason a rich family of optimization algorithms fall under this class. The IterativeOptimizer interface should be used to inform the user that an iterative optimization procedure is implemented under the hood. template < unsigned int N > class IterativeOptimizer : public Optimizer < N > { ... }; Info The IterativeOptimizer class does not implement the general schema of an iterative optimizer, whose implementation is left to the derived classes. Forcing any deriving class to follow a too rigid schema could introduce useless complications in the implementation of the optimization procedure. This class introduce anyway the possibility to control in some way the flow of execution of an iterative optimizer. For example it would be possible to monitor during the execution of the algorithm itself some quantities of interest for the particular problem at hand and force the stop of the procedure on the base of some custom stopping criterion bypassing the default one. The way this mechanism is reached is by extending any concrete implementation of the IterativeOptimizer class and overloading the wanted methods exposed by IterativeOptimizer itself. Developer's advice Is up to the derived classes of IterativeOptimizer to implement properly the stated mechanism. When you want to give the possibility to execute a (possibly) custom action of a (possibly) deriving class you should insert i.e. this->init() for executing a custom initialization. See the semantic of IterativeOptimizer ' methods to see what kind of customizations can be added and decide the proper place where to execute the action.","title":"IterativeOptimizer "},{"location":"core/OPT/Optimizer/#methods","text":"virtual void init (); This method should be called once before entering the iterative loop. virtual void preStep (); This method should be inserted in the iterative loop, possibly as first loop instruction. In any case insert it before the update step. virtual void postStep (); This method should be inserted in the iterative loop. Insert it after the update step. A good place is immediately after the error update. virtual bool stopCondition (); This method should be called in a while of for statement togheter with the default termination criteria. The good practice is to write something like while ( ! default_stopping_condition () && ! this -> stopCondition ()) { ... } It must return false if the custom stopping condition is not met. virtual void finalize (); This method should be called once outside the iterative loop, possibly right before the return statement. As an example consider the implementation of the optimization routine for the GradientDescent 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // gradient descent optimization routine template < unsigned int N > std :: pair < SVector < N > , double > GradientDescentOptimizer < N >:: findMinimum (){ this -> init (); // execute custom action // algorithm initialization x_old = x0 ; unsigned int numIteration = 0 ; // standard termination criteria based on l^2 norm of the gradient error = objective . derive ()( x_old ). squaredNorm (); while ( numIteration < maxIteration && error > tolerance && ! this -> stopCondition ()){ this -> preStep (); // execute custom action // compute exact gradient gradientExact = objective . derive ()( x_old ); // update step x_new = x_old - step * gradientExact ; // error update: standard termination criteria based on l^2 norm of the gradient error = gradientExact . squaredNorm (); this -> postStep (); // execute custom action // prepare next iteration x_old = x_new ; numIteration ++ ; } this -> finalize (); // execute custom action return std :: pair < SVector < N > , double > ( x_old , objective ( x_old )); } Tip The IterativeOptimizer class offers a std::unordered_map<std::string, std::list<double>> controllerData which can be used by a customization to store or record values needed to perform custom actions. Use the init() method to initialize any field you might require before the actual optimization starts.","title":"Methods"},{"location":"core/OPT/ScalarField/","text":"ScalarField core/OPT/ScalarField.h Extends: - A template class for handling scalar fields f : \\mathbb{R}^N \\rightarrow \\mathbb{R} template < unsigned int N > class ScalarField { ... }; Note A field wrapped by this template doesn't guarantee any regularity condition. You can wrap any scalar field which is just evaluable at any point. The definition of a formal derivative is not required. See DifferentiableScalarField or TwiceDifferentiableScalarField for inherited classes which assume specific regularity conditions. Methods ScalarField ( std :: function < double ( SVector < N > ) > f_ ) Constructor. Args Description std::function<double(SVector<N>)> f_ An std::function implementing the analytical expression of the field f taking an N dimensional point in input and returning a double in output inline double evaluateAtPoint ( const Point < N >& x ) Returns the evaluation of the field at point x. Args Description const SVector<N>& x The point in \\mathbb{R}^N where to evaluate the field inline double operator ()( SVector < N >& x ) Returns the evaluation of the field at point x. Preserves the std::function syntax. Args Description SVector<N>& x The point in \\mathbb{R}^N where to evaluate the field SVector < N > getGradientApprox ( const SVector < N >& x , double step ) const Returns the numerical approximation of the gradient of f at point x. The partial derivatives of the field are approximated via central differences according to the following expression ( e_i denoting the normal unit vector along direction i ) \\frac{\\partial f}{\\partial x_i} \\approx \\frac{f(x + he_i) - f(x - he_i)}{2h} Args Description const SVector<N>& x The point in \\mathbb{R}^N where to approximate the gradient of the field double step The value of h in the central difference formula Warning In principle the approximation of the partial derivatives require the field f to be just evaluable at point x. Anyway if the field is not differentiable at point x the approximation might cause problems. SMatrix < N > getHessianApprox ( const SVector < N >& x , double step ) const Returns the numerical approximation of the hessian matrix of f at point x. The partial derivatives of the field are approximated via central differences according to the following expressions ( e_i denoting the normal unit vector along direction i ) \\begin{aligned} &\\frac{\\partial^2 f}{\\partial x_i \\partial x_i} &&\\approx \\frac{-f(x + 2he_i) + 16f(x + he_i) - 30f(x) + 16f(x - he_i) - f(x - 2he_i)}{12h^2} \\\\ &\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} &&\\approx \\frac{f(x + he_i + he_j) - f(x + he_i - he_j) - 16f(x - he_i + he_j) + f(x - he_i - he_j)}{4h^2} \\end{aligned} Args Description const SVector<N>& x The point in \\mathbb{R}^N where to approximate the hessian of the field double step The value of h in the central difference formula Warning In principle the approximation of the partial derivatives require the field f to be just evaluable at point x. Anyway if the field is not differentiable at point x the approximation might cause problems. Examples 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // define the field analytical expression: 2*x^2 - 2*y^2*x std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) - 2 * std :: pow ( x [ 1 ], 2 ) * x [ 0 ]; }; // create ScalarField ScalarField < 2 > field ( g ); std :: cout << \"evaluation of field at point\" << std :: endl ; std :: cout << fun . evaluateAtPoint ( SVector < 2 > ( 4 , 1 )) << std :: endl ; SVector < 2 > grad = fun . getGradientApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of gradient at point\" << std :: endl ; std :: cout << grad << std :: endl ; SMatrix < 2 > hessian = fun . getHessianApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of hessian at point\" << std :: endl ; std :: cout << hessian << std :: endl ;","title":"ScalarField"},{"location":"core/OPT/ScalarField/#scalarfield","text":"core/OPT/ScalarField.h Extends: - A template class for handling scalar fields f : \\mathbb{R}^N \\rightarrow \\mathbb{R} template < unsigned int N > class ScalarField { ... }; Note A field wrapped by this template doesn't guarantee any regularity condition. You can wrap any scalar field which is just evaluable at any point. The definition of a formal derivative is not required. See DifferentiableScalarField or TwiceDifferentiableScalarField for inherited classes which assume specific regularity conditions.","title":"ScalarField"},{"location":"core/OPT/ScalarField/#methods","text":"ScalarField ( std :: function < double ( SVector < N > ) > f_ ) Constructor. Args Description std::function<double(SVector<N>)> f_ An std::function implementing the analytical expression of the field f taking an N dimensional point in input and returning a double in output inline double evaluateAtPoint ( const Point < N >& x ) Returns the evaluation of the field at point x. Args Description const SVector<N>& x The point in \\mathbb{R}^N where to evaluate the field inline double operator ()( SVector < N >& x ) Returns the evaluation of the field at point x. Preserves the std::function syntax. Args Description SVector<N>& x The point in \\mathbb{R}^N where to evaluate the field SVector < N > getGradientApprox ( const SVector < N >& x , double step ) const Returns the numerical approximation of the gradient of f at point x. The partial derivatives of the field are approximated via central differences according to the following expression ( e_i denoting the normal unit vector along direction i ) \\frac{\\partial f}{\\partial x_i} \\approx \\frac{f(x + he_i) - f(x - he_i)}{2h} Args Description const SVector<N>& x The point in \\mathbb{R}^N where to approximate the gradient of the field double step The value of h in the central difference formula Warning In principle the approximation of the partial derivatives require the field f to be just evaluable at point x. Anyway if the field is not differentiable at point x the approximation might cause problems. SMatrix < N > getHessianApprox ( const SVector < N >& x , double step ) const Returns the numerical approximation of the hessian matrix of f at point x. The partial derivatives of the field are approximated via central differences according to the following expressions ( e_i denoting the normal unit vector along direction i ) \\begin{aligned} &\\frac{\\partial^2 f}{\\partial x_i \\partial x_i} &&\\approx \\frac{-f(x + 2he_i) + 16f(x + he_i) - 30f(x) + 16f(x - he_i) - f(x - 2he_i)}{12h^2} \\\\ &\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} &&\\approx \\frac{f(x + he_i + he_j) - f(x + he_i - he_j) - 16f(x - he_i + he_j) + f(x - he_i - he_j)}{4h^2} \\end{aligned} Args Description const SVector<N>& x The point in \\mathbb{R}^N where to approximate the hessian of the field double step The value of h in the central difference formula Warning In principle the approximation of the partial derivatives require the field f to be just evaluable at point x. Anyway if the field is not differentiable at point x the approximation might cause problems.","title":"Methods"},{"location":"core/OPT/ScalarField/#examples","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // define the field analytical expression: 2*x^2 - 2*y^2*x std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) - 2 * std :: pow ( x [ 1 ], 2 ) * x [ 0 ]; }; // create ScalarField ScalarField < 2 > field ( g ); std :: cout << \"evaluation of field at point\" << std :: endl ; std :: cout << fun . evaluateAtPoint ( SVector < 2 > ( 4 , 1 )) << std :: endl ; SVector < 2 > grad = fun . getGradientApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of gradient at point\" << std :: endl ; std :: cout << grad << std :: endl ; SMatrix < 2 > hessian = fun . getHessianApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of hessian at point\" << std :: endl ; std :: cout << hessian << std :: endl ;","title":"Examples"},{"location":"core/OPT/TwiceDifferentiableScalarField/","text":"TwiceDifferentiableScalarField core/OPT/ScalarField.h Extends: DifferentiableScalarField Template class used to represent a scalar field f : \\mathbb{R}^N \\rightarrow \\mathbb{R} whose hessian function H(f) : \\mathbb{R}^N \\rightarrow \\mathbb{R}^{N \\times N} is known analitically at every point. template < unsigned int N > class TwiceDifferentiableScalarField : public DifferentiableScalarField < N > { ... }; Methods TwiceDifferentiableScalarField ( std :: function < double ( SVector < N > ) > f_ , std :: function < SVector < N > ( SVector < N > ) > df_ , std :: function < SMatrix < N > ( SVector < N > ) > ddf_ ) Constructor Args Description std::function<double(SVector<N>)> f_ An std::function implementing the analytical expression of the field f taking an N dimensional point in input and returning a double in output std::function<SVector<N>(SVector<N>)> df_ An std::function implementing the analytical expression of the vector field \\nabla f taking an N dimensional point in input and returning an N dimensional point in output representing the gradient expression std::function<SMatrix<N>(SVector<N>)> ddf_ An std::function implementing the analytical expression of the hessian function H(f) taking an N dimensional point in input and returning an N dimensional square matrix in output representing the hessian expression std :: function < SMatrix < N > ( SVector < N > ) > deriveTwice () const override ; Returns the analytical expression of the field's hessian H(f) : \\mathbb{R}^N \\rightarrow \\mathbb{R}^{N \\times N} as a Callable object. Examples Define a scalar field f(x,y) = 2x^2 + 2y^2 having exact gradient equal to \\nabla f = [4x, 4y]^T and exact hessian matrix given by H(f) = \\begin{bmatrix} 4 & 0 \\\\ 0 & 4 \\end{bmatrix} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // define the field analytical expression: 2*x^2 + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + 2 * std :: pow ( x [ 1 ], 2 ); }; // define analytical expression of gradient field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ], 4 * x [ 1 ]}); }; // define analytical expression of hessian matrix std :: function < SMatrix < 2 > ( SVector < 2 > ) > ddg = []( SVector < 2 > x ) -> SMatrix < 2 > { return SMatrix < 2 > ({{ 4 , 0 }, { 0 , 4 }}); }; // define twice differentiable field TwiceDifferentiableScalarField < 2 > field ( g , dg , ddg ); std :: cout << \"evaluation of field at point\" << std :: endl ; std :: cout << field . evaluateAtPoint ( SVector < 2 > ( 4 , 1 )) << std :: endl ; // get approximation of hessian at point SVector < 2 > hess = field . getHessianApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of gradient at point\" << std :: endl ; std :: cout << hess << std :: endl ; // evaluate exact hessian at point SVector < 2 > exactHess = field . deriveTwice ()( SVector < 2 > ( 2 , 1 )); std :: cout << \"exact hessian at point\" << std :: endl ; std :: cout << exactHess << std :: endl ;","title":"TwiceDifferentiableScalarField"},{"location":"core/OPT/TwiceDifferentiableScalarField/#twicedifferentiablescalarfield","text":"core/OPT/ScalarField.h Extends: DifferentiableScalarField Template class used to represent a scalar field f : \\mathbb{R}^N \\rightarrow \\mathbb{R} whose hessian function H(f) : \\mathbb{R}^N \\rightarrow \\mathbb{R}^{N \\times N} is known analitically at every point. template < unsigned int N > class TwiceDifferentiableScalarField : public DifferentiableScalarField < N > { ... };","title":"TwiceDifferentiableScalarField"},{"location":"core/OPT/TwiceDifferentiableScalarField/#methods","text":"TwiceDifferentiableScalarField ( std :: function < double ( SVector < N > ) > f_ , std :: function < SVector < N > ( SVector < N > ) > df_ , std :: function < SMatrix < N > ( SVector < N > ) > ddf_ ) Constructor Args Description std::function<double(SVector<N>)> f_ An std::function implementing the analytical expression of the field f taking an N dimensional point in input and returning a double in output std::function<SVector<N>(SVector<N>)> df_ An std::function implementing the analytical expression of the vector field \\nabla f taking an N dimensional point in input and returning an N dimensional point in output representing the gradient expression std::function<SMatrix<N>(SVector<N>)> ddf_ An std::function implementing the analytical expression of the hessian function H(f) taking an N dimensional point in input and returning an N dimensional square matrix in output representing the hessian expression std :: function < SMatrix < N > ( SVector < N > ) > deriveTwice () const override ; Returns the analytical expression of the field's hessian H(f) : \\mathbb{R}^N \\rightarrow \\mathbb{R}^{N \\times N} as a Callable object.","title":"Methods"},{"location":"core/OPT/TwiceDifferentiableScalarField/#examples","text":"Define a scalar field f(x,y) = 2x^2 + 2y^2 having exact gradient equal to \\nabla f = [4x, 4y]^T and exact hessian matrix given by H(f) = \\begin{bmatrix} 4 & 0 \\\\ 0 & 4 \\end{bmatrix} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // define the field analytical expression: 2*x^2 + 2*y^2 std :: function < double ( SVector < 2 > ) > g = []( SVector < 2 > x ) -> double { return 2 * std :: pow ( x [ 0 ], 2 ) + 2 * std :: pow ( x [ 1 ], 2 ); }; // define analytical expression of gradient field std :: function < SVector < 2 > ( SVector < 2 > ) > dg = []( SVector < 2 > x ) -> SVector < 2 > { return SVector < 2 > ({ 4 * x [ 0 ], 4 * x [ 1 ]}); }; // define analytical expression of hessian matrix std :: function < SMatrix < 2 > ( SVector < 2 > ) > ddg = []( SVector < 2 > x ) -> SMatrix < 2 > { return SMatrix < 2 > ({{ 4 , 0 }, { 0 , 4 }}); }; // define twice differentiable field TwiceDifferentiableScalarField < 2 > field ( g , dg , ddg ); std :: cout << \"evaluation of field at point\" << std :: endl ; std :: cout << field . evaluateAtPoint ( SVector < 2 > ( 4 , 1 )) << std :: endl ; // get approximation of hessian at point SVector < 2 > hess = field . getHessianApprox ( SVector < 2 > ( 2 , 1 ), 0.001 ); std :: cout << \"approximation of gradient at point\" << std :: endl ; std :: cout << hess << std :: endl ; // evaluate exact hessian at point SVector < 2 > exactHess = field . deriveTwice ()( SVector < 2 > ( 2 , 1 )); std :: cout << \"exact hessian at point\" << std :: endl ; std :: cout << exactHess << std :: endl ;","title":"Examples"}]}